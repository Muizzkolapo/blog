<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Apply the gradient descent algorithm to custom functions | Muizzkolapo</title>
<meta name="keywords" content="">
<meta name="description" content="Applying the gradient descent algorithm to find the minimum of the following function of four variables
$f(x, y, z, w) = \frac{1}{4}(2-x)^2 &#43; (3y-5)^4 &#43; e^{2z^4 &#43; w^2}$
Introduction Gradient is an algorithm used to find the parameters that minimizes a function. We will be using the function above to implement gradient descent. To implement a gradient descent algorithm there are some important ingredients to be used which includes;
The function The partial derivative of all the function The gradient descent algorithm finds the best path to descend to the minimum points in a function by finding the slope of the tangent of the function.">
<meta name="author" content="Muizz Kolapo">
<link rel="canonical" href="https://muizzkolapo.github.io/blog/docs/gradient_descent_custom/">
<link crossorigin="anonymous" href="/blog/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css" integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://muizzkolapo.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://muizzkolapo.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://muizzkolapo.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://muizzkolapo.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://muizzkolapo.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Apply the gradient descent algorithm to custom functions" />
<meta property="og:description" content="Applying the gradient descent algorithm to find the minimum of the following function of four variables
$f(x, y, z, w) = \frac{1}{4}(2-x)^2 &#43; (3y-5)^4 &#43; e^{2z^4 &#43; w^2}$
Introduction Gradient is an algorithm used to find the parameters that minimizes a function. We will be using the function above to implement gradient descent. To implement a gradient descent algorithm there are some important ingredients to be used which includes;
The function The partial derivative of all the function The gradient descent algorithm finds the best path to descend to the minimum points in a function by finding the slope of the tangent of the function." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://muizzkolapo.github.io/blog/docs/gradient_descent_custom/" /><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2023-03-04T09:13:17+00:00" />
<meta property="article:modified_time" content="2023-03-04T09:13:17+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Apply the gradient descent algorithm to custom functions"/>
<meta name="twitter:description" content="Applying the gradient descent algorithm to find the minimum of the following function of four variables
$f(x, y, z, w) = \frac{1}{4}(2-x)^2 &#43; (3y-5)^4 &#43; e^{2z^4 &#43; w^2}$
Introduction Gradient is an algorithm used to find the parameters that minimizes a function. We will be using the function above to implement gradient descent. To implement a gradient descent algorithm there are some important ingredients to be used which includes;
The function The partial derivative of all the function The gradient descent algorithm finds the best path to descend to the minimum points in a function by finding the slope of the tangent of the function."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Docs",
      "item": "https://muizzkolapo.github.io/blog/docs/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Apply the gradient descent algorithm to custom functions",
      "item": "https://muizzkolapo.github.io/blog/docs/gradient_descent_custom/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Apply the gradient descent algorithm to custom functions",
  "name": "Apply the gradient descent algorithm to custom functions",
  "description": "Applying the gradient descent algorithm to find the minimum of the following function of four variables\n$f(x, y, z, w) = \\frac{1}{4}(2-x)^2 + (3y-5)^4 + e^{2z^4 + w^2}$\nIntroduction Gradient is an algorithm used to find the parameters that minimizes a function. We will be using the function above to implement gradient descent. To implement a gradient descent algorithm there are some important ingredients to be used which includes;\nThe function The partial derivative of all the function The gradient descent algorithm finds the best path to descend to the minimum points in a function by finding the slope of the tangent of the function.",
  "keywords": [
    
  ],
  "articleBody": "Applying the gradient descent algorithm to find the minimum of the following function of four variables\n$f(x, y, z, w) = \\frac{1}{4}(2-x)^2 + (3y-5)^4 + e^{2z^4 + w^2}$\nIntroduction Gradient is an algorithm used to find the parameters that minimizes a function. We will be using the function above to implement gradient descent. To implement a gradient descent algorithm there are some important ingredients to be used which includes;\nThe function The partial derivative of all the function The gradient descent algorithm finds the best path to descend to the minimum points in a function by finding the slope of the tangent of the function. We will be implementing the batch gradient descent algorithm in this task. The slope of the tangent tells us the direction of our descent.\nGradient descent procedure The algorithm starts off with initial values for the parameters of the function. These could be 0.0 or a small random value. We observed that using zero initialization for this algorithm makes it impossible for us to update some of the parameters such as (w and z) due to the exponentials. We initiated the algorithm using random initialization to solve this problem.\nThe cost of the parameters is evaluated by inserting them into the function and calculating the cost of using this parameters.\nThe derivative of the function is calculated. The derivative of the function as stated above is the slope of the function. We need to know the slope so that we know the direction (sign) to move the parameter values in order to get a lower cost on the next iteration.\nNow that we know direction or slope of the function, we can now update the parameter values. We used the learning rate to state the size of the step to take during each iteration.\nThis process is repeated until the cost of the parameters close to zero or minimum enough.\nFinding the partial derivative of independent variables in equation above we will be applying the partial derivative, power rule and chain rule to the function above. $$\\frac{d(f(x, y, z, w))}{{dx}} = (x-2)/2 $$ $$\\frac{d(f(x, y, z, w))}{{dy}} = 12((3y)-5)^3 $$ $$\\frac{d(f(x, y, z, w))}{{dz}} = (8z^3)e^{2z^4 + w^2} $$ $$\\frac{d(f(x, y, z, w))}{{dz}} = (2w)e^{2z^4 + w^2} $$\nAfter finding the derivative of the function with respect to each element in the equation, we created a function “fun” which returns the result of the original equation whenever we give it inputs as argument. We then proceeded to create a function for each of the partial derivatives as this would be used when implementing the gradient descent algorithm. We added a tolerance of 0.01 and step seize of 0.03.\nimport numpy as np import math import matplotlib.pyplot as plt import seaborn as sns import random import pandas as pd %matplotlib inline random.seed(20210402) x=random.random() y=random.random() z=random.random() w=random.random() #partial derivative (1/4(2-x)^2) + (3y-5)^4 + e^(2z^4 + w^2) #define the function def fun(x,y,z,w): return ((1/4)*(2-x)**2) + ((3*y)-5)**4 + math.exp((2*(z**4))+(w**2)) #define the derivative w.r.t x def der_x(x): return (x-2)/2 #define the derivative w.r.t y def der_y(y): return 12*((3*y)-5)**3 #define the derivative w.r.t z def der_z(z,w): return ((8)*(z**3))*math.exp((2*(z**4))+(w**2)) #define the derivative w.r.t w def der_w(w,z): return (2*w)*math.exp((2*(z**4))+(w**2)) #define the grad descent def step(init_param,grad,step_size): return (init_param - (step_size * grad)) #define the counter i = 0 #define the tolerance tolerance = 0.01 step_size = 0.03 #create an empty list my_list =[] #loop till we find the minimum point while True: i +=1 #print(x,y,z,w,fun(x,y,z,w)) my_list.append([x,y,z,w,fun(x,y,z,w)]) #assign derivative of each parameter grad_x = der_x(x) grad_y = der_x(y) grad_z = der_z(z,w) grad_w = der_w(w,z) #apply the step function next_x = step(x, grad_x, step_size) next_y = step(y, grad_y, step_size) next_z = step(z, grad_z, step_size) next_w = step(w, grad_w, step_size) #apply tolerance to break out of the loop if (np.sqrt(((x-next_x)**2 + (y-next_y)**2 + (z-next_z)**2 + (w-next_w)**2)) \u003c tolerance): break #assign output to variables x,y,z,w x,y,z,w= next_x,next_y,next_z,next_w print(\"It took {} epochs, for the algorithm to find the minimum point\".format(i)) #load the independent variables into a dataaframe parameters = pd.DataFrame(np.array(my_list), columns = ['x','y','z','w','cost_fun']) parameters['zero'] = pd.Series([0 for x in range(len(parameters.index))], index=parameters.index) It took 67 epochs, for the algorithm to find the minimum point It was observed that the alorithm took 67 iterations to find the parameters that minimizes our function, the initial values of the parameter influences gradient descent and how long it takes to descend, if we change the step size and parameter initiation we would observe the number of iteration required to converge at the local optima would be different from what we currently have.\nparameters.head() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } parameters.tail() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import plotly.graph_objects as go fig = go.Figure(data = go.Contour( x=parameters.x, # horizontal axis y=parameters.y, # vertical axis z=parameters.cost_fun, colorscale='Electric', )) fig.show() import plotly.graph_objects as go fig = go.Figure(data = go.Contour( x=parameters.z, # horizontal axis y=parameters.w, # vertical axis z=parameters.cost_fun, colorscale='Electric', )) fig.show() from plotly.subplots import make_subplots import plotly.graph_objects as go fig = go.Figure() fig.add_trace(go.Scatter3d(x=parameters.x, y=parameters.zero, z=parameters.cost_fun, mode=\"markers+text\", name=\"Markers and Text\", text=[\"X\"], textposition=\"bottom center\")) fig.add_trace(go.Scatter3d(x=parameters.y, y=parameters.zero, z=parameters.cost_fun, mode=\"markers+text\", name=\"Markers and Text\", text=[\"Y\"], textposition=\"bottom center\")) fig.add_trace(go.Scatter3d(x=parameters.z, y=parameters.zero, z=parameters.cost_fun, mode=\"markers+text\", name=\"Markers and Text\", text=[\"Z\"], textposition=\"top center\")) fig.add_trace(go.Scatter3d(x=parameters.w, y=parameters.zero, z=parameters.cost_fun, mode=\"markers+text\", name=\"Markers and Text\", text=[\"W\"], textposition=\"top center\")) fig.update_layout(showlegend=False, title=\"3D Plot gradient descent\", font=dict( family=\"Courier New, monospace\", color=\"RebeccaPurple\" ) ) fig.show() Results Visualizing the outcome of the implementation of the gradient descent algorithm we can observe that gradient descent was able to find the parameters that minimizes the cost function, we used random initialization for selecting the initial starting points to avoid the saturation of our cost function as we observed that using zero initialization makes it impossible for the gradient descent algorithm to update the parameters z and w. The plot for the path taken by the algorithm for the simulataneus update for all the parameters is different but we can observe they all converge at the same value of the cost function regardless of the path taken.The visualization showed that the path taken by variables x and y is different to that which z and w took, but we observe that they all eventually converge at the local optima.\n",
  "wordCount" : "1026",
  "inLanguage": "en",
  "datePublished": "2023-03-04T09:13:17Z",
  "dateModified": "2023-03-04T09:13:17Z",
  "author":{
    "@type": "Person",
    "name": "Muizz Kolapo"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://muizzkolapo.github.io/blog/docs/gradient_descent_custom/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Muizzkolapo",
    "logo": {
      "@type": "ImageObject",
      "url": "https://muizzkolapo.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://muizzkolapo.github.io/blog/" accesskey="h" title="Muizzkolapo (Alt + H)">Muizzkolapo</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://muizzkolapo.github.io/blog/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://muizzkolapo.github.io/blog/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://muizzkolapo.github.io/blog/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Apply the gradient descent algorithm to custom functions
    </h1>
    <div class="post-meta"><span title='2023-03-04 09:13:17 +0000 UTC'>March 4, 2023</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Muizz Kolapo

</div>
  </header> 
  <div class="post-content"><p>Applying the gradient descent algorithm to find the minimum of the following function of four
variables</p>
<p>$f(x, y, z, w) = \frac{1}{4}(2-x)^2 + (3y-5)^4 + e^{2z^4 + w^2}$</p>
<h4 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h4>
<p>Gradient is an algorithm used to find the parameters that minimizes a function. We will be using the function above to implement gradient descent. To implement a gradient descent algorithm there are some important ingredients to be used which includes;</p>
<ul>
<li>The function</li>
<li>The partial derivative of all the function</li>
</ul>
<p>The gradient descent algorithm finds the best path to descend to the minimum points in a function by finding the slope of the tangent of the function. We will be implementing the batch gradient descent algorithm in this task. The slope of the tangent tells us the direction of our descent.</p>
<h4 id="gradient-descent-procedure">Gradient descent procedure<a hidden class="anchor" aria-hidden="true" href="#gradient-descent-procedure">#</a></h4>
<p>The algorithm starts off with initial values for the parameters of the function. These could be 0.0 or a small random value. We observed that using zero initialization for this algorithm makes it impossible for us to update some of the parameters such as (w and z) due to the exponentials. We initiated the algorithm using random initialization to solve this problem.</p>
<p>The cost of the parameters is evaluated by inserting them into the function and calculating the cost of using this parameters.</p>
<p>The derivative of the function is calculated. The derivative of the function as stated above is the slope of the function. We need to know the slope so that we know the direction (sign) to move the parameter values in order to get a lower cost on the next iteration.</p>
<p>Now that we know direction or slope of the function, we can now update the parameter values. We used the learning rate to state the size of the step to take during each iteration.</p>
<p>This process is repeated until the cost of the parameters close to zero or minimum enough.</p>
<p><strong>Finding the partial derivative of independent variables in equation above</strong> <!-- raw HTML omitted --></p>
<p>we will be applying the partial derivative, power rule and chain rule to the function above.
$$\frac{d(f(x, y, z, w))}{{dx}} = (x-2)/2 $$
$$\frac{d(f(x, y, z, w))}{{dy}} = 12((3y)-5)^3 $$
$$\frac{d(f(x, y, z, w))}{{dz}} = (8z^3)e^{2z^4 + w^2} $$
$$\frac{d(f(x, y, z, w))}{{dz}} = (2w)e^{2z^4 + w^2} $$</p>
<p>After finding the derivative of the function with respect to each element in the equation, we  created a function &ldquo;fun&rdquo; which returns the result of the original equation whenever we give it inputs as argument. We then proceeded to create a function for each of the partial derivatives as this would be used when implementing the gradient descent algorithm. We added a tolerance of 0.01 and step seize of 0.03.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">%</span>matplotlib inline
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">20210402</span>)
</span></span><span style="display:flex;"><span>x<span style="color:#f92672">=</span>random<span style="color:#f92672">.</span>random()
</span></span><span style="display:flex;"><span>y<span style="color:#f92672">=</span>random<span style="color:#f92672">.</span>random()
</span></span><span style="display:flex;"><span>z<span style="color:#f92672">=</span>random<span style="color:#f92672">.</span>random()
</span></span><span style="display:flex;"><span>w<span style="color:#f92672">=</span>random<span style="color:#f92672">.</span>random()
</span></span><span style="display:flex;"><span><span style="color:#75715e">#partial derivative (1/4(2-x)^2) + (3y-5)^4 + e^(2z^4 + w^2)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fun</span>(x,y,z,w):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span>  ((<span style="color:#ae81ff">1</span><span style="color:#f92672">/</span><span style="color:#ae81ff">4</span>)<span style="color:#f92672">*</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">-</span>x)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">+</span> ((<span style="color:#ae81ff">3</span><span style="color:#f92672">*</span>y)<span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">4</span> <span style="color:#f92672">+</span> math<span style="color:#f92672">.</span>exp((<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>(z<span style="color:#f92672">**</span><span style="color:#ae81ff">4</span>))<span style="color:#f92672">+</span>(w<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the derivative w.r.t x</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">der_x</span>(x):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (x<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the derivative w.r.t y</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">der_y</span>(y):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">12</span><span style="color:#f92672">*</span>((<span style="color:#ae81ff">3</span><span style="color:#f92672">*</span>y)<span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the derivative w.r.t z</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">der_z</span>(z,w):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ((<span style="color:#ae81ff">8</span>)<span style="color:#f92672">*</span>(z<span style="color:#f92672">**</span><span style="color:#ae81ff">3</span>))<span style="color:#f92672">*</span>math<span style="color:#f92672">.</span>exp((<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>(z<span style="color:#f92672">**</span><span style="color:#ae81ff">4</span>))<span style="color:#f92672">+</span>(w<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the derivative w.r.t w</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">der_w</span>(w,z):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>w)<span style="color:#f92672">*</span>math<span style="color:#f92672">.</span>exp((<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>(z<span style="color:#f92672">**</span><span style="color:#ae81ff">4</span>))<span style="color:#f92672">+</span>(w<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the grad descent</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">step</span>(init_param,grad,step_size):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (init_param <span style="color:#f92672">-</span> (step_size <span style="color:#f92672">*</span> grad))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the counter</span>
</span></span><span style="display:flex;"><span>i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#define the tolerance</span>
</span></span><span style="display:flex;"><span>tolerance <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
</span></span><span style="display:flex;"><span>step_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.03</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#create an empty list</span>
</span></span><span style="display:flex;"><span>my_list <span style="color:#f92672">=</span>[]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#loop till we find the minimum point</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>    i <span style="color:#f92672">+=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#print(x,y,z,w,fun(x,y,z,w))</span>
</span></span><span style="display:flex;"><span>    my_list<span style="color:#f92672">.</span>append([x,y,z,w,fun(x,y,z,w)])
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#assign derivative of each parameter</span>
</span></span><span style="display:flex;"><span>    grad_x <span style="color:#f92672">=</span> der_x(x)
</span></span><span style="display:flex;"><span>    grad_y <span style="color:#f92672">=</span> der_x(y)
</span></span><span style="display:flex;"><span>    grad_z <span style="color:#f92672">=</span> der_z(z,w)
</span></span><span style="display:flex;"><span>    grad_w <span style="color:#f92672">=</span> der_w(w,z)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#apply the step function</span>
</span></span><span style="display:flex;"><span>    next_x <span style="color:#f92672">=</span> step(x, grad_x, step_size)
</span></span><span style="display:flex;"><span>    next_y <span style="color:#f92672">=</span> step(y, grad_y, step_size)
</span></span><span style="display:flex;"><span>    next_z <span style="color:#f92672">=</span> step(z, grad_z, step_size)
</span></span><span style="display:flex;"><span>    next_w <span style="color:#f92672">=</span> step(w, grad_w, step_size)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#apply tolerance to break out of the loop</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (np<span style="color:#f92672">.</span>sqrt(((x<span style="color:#f92672">-</span>next_x)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (y<span style="color:#f92672">-</span>next_y)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span>  (z<span style="color:#f92672">-</span>next_z)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (w<span style="color:#f92672">-</span>next_w)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)) <span style="color:#f92672">&lt;</span> tolerance):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#assign output to variables x,y,z,w</span>
</span></span><span style="display:flex;"><span>    x,y,z,w<span style="color:#f92672">=</span> next_x,next_y,next_z,next_w
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;It took </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> epochs, for the algorithm to find the minimum point&#34;</span><span style="color:#f92672">.</span>format(i))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#load the independent variables into a dataaframe</span>
</span></span><span style="display:flex;"><span>parameters <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(np<span style="color:#f92672">.</span>array(my_list), columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;x&#39;</span>,<span style="color:#e6db74">&#39;y&#39;</span>,<span style="color:#e6db74">&#39;z&#39;</span>,<span style="color:#e6db74">&#39;w&#39;</span>,<span style="color:#e6db74">&#39;cost_fun&#39;</span>])
</span></span><span style="display:flex;"><span>parameters[<span style="color:#e6db74">&#39;zero&#39;</span>] <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>Series([<span style="color:#ae81ff">0</span> <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> range(len(parameters<span style="color:#f92672">.</span>index))], index<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>index)
</span></span></code></pre></div><pre><code>It took 67 epochs, for the algorithm to find the minimum point
</code></pre>
<p>It was observed that the alorithm took 67 iterations to find the parameters that minimizes our function, the initial values of the parameter influences gradient descent and how long it takes to descend, if we change the step size and parameter initiation we would observe the number of iteration required to converge at the local optima would be different from what we currently have.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>parameters<span style="color:#f92672">.</span>head()
</span></span></code></pre></div><!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>parameters<span style="color:#f92672">.</span>tail()
</span></span></code></pre></div><!-- raw HTML omitted -->
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> plotly.graph_objects <span style="color:#66d9ef">as</span> go
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> go<span style="color:#f92672">.</span>Figure(data <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>    go<span style="color:#f92672">.</span>Contour(
</span></span><span style="display:flex;"><span>        x<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>x, <span style="color:#75715e"># horizontal axis</span>
</span></span><span style="display:flex;"><span>        y<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>y, <span style="color:#75715e"># vertical axis</span>
</span></span><span style="display:flex;"><span>        z<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>cost_fun,
</span></span><span style="display:flex;"><span>        colorscale<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Electric&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    ))
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img loading="lazy" src="https://github.com/Muizzkolapo/blog/blob/main/content/docs/newplot.png?raw=true" alt="graph"  />
</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> plotly.graph_objects <span style="color:#66d9ef">as</span> go
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> go<span style="color:#f92672">.</span>Figure(data <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>    go<span style="color:#f92672">.</span>Contour(
</span></span><span style="display:flex;"><span>        x<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>z, <span style="color:#75715e"># horizontal axis</span>
</span></span><span style="display:flex;"><span>        y<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>w, <span style="color:#75715e"># vertical axis</span>
</span></span><span style="display:flex;"><span>        z<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>cost_fun,
</span></span><span style="display:flex;"><span>        colorscale<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Electric&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    ))
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img loading="lazy" src="https://github.com/Muizzkolapo/blog/blob/main/content/docs/newplot%20%281%29.png?raw=true" alt="graph"  />
</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> plotly.subplots <span style="color:#f92672">import</span> make_subplots
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> plotly.graph_objects <span style="color:#66d9ef">as</span> go
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> go<span style="color:#f92672">.</span>Figure()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>add_trace(go<span style="color:#f92672">.</span>Scatter3d(x<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>x, y<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>zero, z<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>cost_fun,    mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;markers+text&#34;</span>,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Markers and Text&#34;</span>,
</span></span><span style="display:flex;"><span>    text<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;X&#34;</span>],
</span></span><span style="display:flex;"><span>    textposition<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;bottom center&#34;</span>))
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>add_trace(go<span style="color:#f92672">.</span>Scatter3d(x<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>y, y<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>zero, z<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>cost_fun,    mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;markers+text&#34;</span>,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Markers and Text&#34;</span>,
</span></span><span style="display:flex;"><span>    text<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;Y&#34;</span>],
</span></span><span style="display:flex;"><span>    textposition<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;bottom center&#34;</span>))
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>add_trace(go<span style="color:#f92672">.</span>Scatter3d(x<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>z, y<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>zero, z<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>cost_fun,    mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;markers+text&#34;</span>,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Markers and Text&#34;</span>,
</span></span><span style="display:flex;"><span>    text<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;Z&#34;</span>],
</span></span><span style="display:flex;"><span>    textposition<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;top center&#34;</span>))
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>add_trace(go<span style="color:#f92672">.</span>Scatter3d(x<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>w, y<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>zero, z<span style="color:#f92672">=</span>parameters<span style="color:#f92672">.</span>cost_fun,    mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;markers+text&#34;</span>,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Markers and Text&#34;</span>,
</span></span><span style="display:flex;"><span>    text<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;W&#34;</span>],
</span></span><span style="display:flex;"><span>    textposition<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;top center&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>update_layout(showlegend<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;3D Plot gradient descent&#34;</span>,
</span></span><span style="display:flex;"><span>    font<span style="color:#f92672">=</span>dict(
</span></span><span style="display:flex;"><span>        family<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Courier New, monospace&#34;</span>,
</span></span><span style="display:flex;"><span>        color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;RebeccaPurple&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img loading="lazy" src="https://raw.githubusercontent.com/Muizzkolapo/blog/main/content/docs/newplot%20%283%29.png" alt="graph"  />
</p>
<h4 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h4>
<p>Visualizing the outcome of the implementation of the gradient descent algorithm we can observe that gradient descent was able to find the parameters that minimizes the cost function, we used random initialization for selecting the initial starting points to avoid the saturation of our cost function as we observed that using zero initialization makes it impossible for the gradient descent algorithm to update the parameters z and w. The plot for the path taken by the algorithm for the simulataneus update for all the parameters is different but we can observe they all converge at the same value of the cost function regardless of the path taken.The visualization showed that the path taken by variables x and y is different to that which z and w took, but we observe that they all eventually converge at the local optima.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Apply the gradient descent algorithm to custom functions on twitter"
        href="https://twitter.com/intent/tweet/?text=Apply%20the%20gradient%20descent%20algorithm%20to%20custom%20functions&amp;url=https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f&amp;hashtags=">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Apply the gradient descent algorithm to custom functions on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f&amp;title=Apply%20the%20gradient%20descent%20algorithm%20to%20custom%20functions&amp;summary=Apply%20the%20gradient%20descent%20algorithm%20to%20custom%20functions&amp;source=https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Apply the gradient descent algorithm to custom functions on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f&title=Apply%20the%20gradient%20descent%20algorithm%20to%20custom%20functions">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Apply the gradient descent algorithm to custom functions on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Apply the gradient descent algorithm to custom functions on whatsapp"
        href="https://api.whatsapp.com/send?text=Apply%20the%20gradient%20descent%20algorithm%20to%20custom%20functions%20-%20https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Apply the gradient descent algorithm to custom functions on telegram"
        href="https://telegram.me/share/url?text=Apply%20the%20gradient%20descent%20algorithm%20to%20custom%20functions&amp;url=https%3a%2f%2fmuizzkolapo.github.io%2fblog%2fdocs%2fgradient_descent_custom%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://muizzkolapo.github.io/blog/">Muizzkolapo</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
